\documentclass[12pt,letterpaper]{article}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{fullpage}
\usepackage{lastpage}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage[margin=3cm]{geometry}
\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.05in}

% Edit these as appropriate
\newcommand\course{CS646}
\newcommand\semester{Fall 2014}     % <-- current semester
\newcommand\hwnum{1}                  % <-- homework number
\newcommand\yourname{Sneha Shankar Narayan} % <-- your name

\fancypagestyle{firstpage}{
\headheight 30pt
\lhead{\yourname\ \\\course\ --- \semester}
\chead{\textbf{\large Report on P \hwnum}}
\rhead{snehas@cs.umass.edu}
}
\thispagestyle{firstpage}


\headsep 15pt

\begin{document}
\subsection*{Implementation choices}
\subsection*{Time Analysis}
\subsection*{Compare the statistics of small with those of the other run(s) you did. What are the differences?  Can you explain them?}
\subsection*{What are the implications of what you found to designing an IR system?  For example, how might it affect your use of term weights in an algorithm?}

\section*{Large collection}

\subsection*{Graph the Zipf-related data and explain whether Zipf's Law holds on this data}
\subsection*{Graph the vocabulary growth and explain whether Heap's Law holds}
\subsection*{For each of these words, list the 10 words with the strongest association and discuss: powerful, strong, butter, salt}
\subsection*{For each of these words, list the entropy of the word and the 5 words most likely to follow them -- i.e., P(w2|w1): Washington, James, church}
\subsection*{For the same words as in (4), list the 5 words most likely to precede the word.}



\end{document}